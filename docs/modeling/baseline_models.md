# Reporte del Modelo Baseline

Este documento contiene los resultados de los modelos entrenados.

## Descripci贸n de los modelos

1. XGBoost
XGBoost (Extreme Gradient Boosting) es un algoritmo basado en 谩rboles de decisi贸n que utiliza un enfoque de ensamble para mejorar la precisi贸n del modelo. Se construyen varios 谩rboles de decisi贸n de manera secuencial, y cada nuevo 谩rbol intenta corregir los errores cometidos por los 谩rboles anteriores. Este modelo es altamente eficiente, y es muy utilizado en competencias de machine learning debido a su capacidad para manejar tanto datos lineales como no lineales. Adem谩s, XGBoost es conocido por su velocidad y precisi贸n, y es particularmente 煤til para grandes vol煤menes de datos.

2. MLPClassifier (Perceptr贸n Multicapa)
El MLPClassifier es un tipo de red neuronal que utiliza m煤ltiples capas de perceptrones para procesar datos de entrada y realizar clasificaciones. Este modelo es capaz de aprender patrones complejos en los datos, lo que lo hace adecuado para problemas no lineales. A diferencia de los 谩rboles de decisi贸n, las redes neuronales pueden capturar relaciones m谩s complejas entre las caracter铆sticas de entrada. El MLPClassifier se entrena utilizando el algoritmo de retropropagaci贸n y es muy flexible en cuanto a la arquitectura de las redes neuronales.

3. LightGBM
LightGBM (Light Gradient Boosting Machine) es otro algoritmo basado en boosting, pero se diferencia de XGBoost en que es m谩s r谩pido y consume menos memoria. Utiliza una t茅cnica de histogramas para reducir el costo computacional, lo que lo hace eficiente con grandes vol煤menes de datos. LightGBM es particularmente 煤til para problemas en los que se manejan grandes conjuntos de datos y se necesitan tiempos de entrenamiento r谩pidos.

4. Random Forest
Random Forest es un modelo de ensamble que utiliza m煤ltiples 谩rboles de decisi贸n para mejorar la precisi贸n general del modelo. Cada 谩rbol en el bosque es entrenado en un subconjunto aleatorio de los datos, y luego se realiza una votaci贸n para determinar la predicci贸n final. Este enfoque ayuda a reducir el sobreajuste, haciendo que el modelo sea robusto incluso con datos ruidosos.

5. Regresi贸n Log铆stica
La regresi贸n log铆stica es un modelo de clasificaci贸n binaria que estima la probabilidad de que una entrada pertenezca a una clase espec铆fica. Este modelo es muy simple y eficiente para problemas de clasificaci贸n, pero generalmente tiene un rendimiento inferior cuando los datos no son lineales.


## Variables de entrada

Lista de las variables de entrada utilizadas en el modelo.

- time
- ejection_fraction
- serum_creatinine

## Variable objetivo

Nombre de la variable objetivo utilizada en el modelo.

- DEATH_EVENT

## Evaluaci贸n del modelo

### M茅tricas de evaluaci贸n

Descripci贸n de las m茅tricas utilizadas para evaluar el rendimiento del modelo.

#### 1. Accuracy
Mide la proporci贸n de predicciones correctas sobre el total de predicciones realizadas. Es decir, cu谩ntas veces el modelo acert贸 entre todos los casos.

- Formula:
  
  TP = Verdaderos positivos
  TN = Verdaderos negativos
  FP = Falsos positivos
  FN = Falsos negativos

- Interpretaci贸n:
  Una precisi贸n del 100% indica que el modelo hizo todas las predicciones correctas, pero puede ser enga帽osa si las clases est谩n desbalanceadas.

#### 2. Precision 
Mide la proporci贸n de predicciones positivas correctas sobre todas las predicciones que el modelo hizo como positivas. Es 煤til cuando el costo de un falso positivo es alto.

- Formula:
  


- Interpretaci贸n:
   Una alta precisi贸n significa que cuando el modelo predice positivo, es muy probable que est茅 en lo cierto. Se usa cuando es m谩s importante evitar que un falso positivo ocurra.

#### 3. Recall  
Mide la proporci贸n de casos positivos reales que el modelo fue capaz de identificar correctamente. Es 煤til cuando el costo de un falso negativo es alto.

- Formula:
  


- Interpretaci贸n:
   Un alto recall significa que el modelo es bueno para identificar casos positivos, incluso si a veces comete falsos positivos. Es cr铆tico en situaciones donde perder casos positivos (falsos negativos) tiene consecuencias graves.

#### 4. F1 Score  
Es el promedio arm贸nico entre la precisi贸n y el recall, y se utiliza cuando es necesario un balance entre ambos. Un puntaje F1 alto indica que tanto la precisi贸n como el recall son buenos.

- Formula:
  


- Interpretaci贸n:
   El F1 es particularmente 煤til cuando se enfrentan a datos desbalanceados (m谩s instancias de una clase que de otra) y cuando tanto los falsos positivos como los falsos negativos tienen un impacto significativo.

#### 5. AUC-ROC  
Mide la capacidad del modelo para distinguir entre las clases, calculando el 谩rea bajo la curva ROC (Receiver Operating Characteristic), que es un gr谩fico que muestra la tasa de verdaderos positivos frente a la tasa de falsos positivos.

- Formula:
  


- Interpretaci贸n:
   Un AUC cercano a 1 indica que el modelo tiene una buena capacidad para diferenciar entre las clases. Un AUC de 0.5 indica que el modelo no tiene capacidad predictiva mejor que el azar.

#### 6. Log Loss  
Eval煤a la calidad de las probabilidades de predicci贸n del modelo, penalizando las predicciones incorrectas con mayor severidad. Se usa principalmente en problemas de clasificaci贸n probabil铆stica.

- Formula:
  yi es el valor real de la clase (0 o 1)
   es la probabilidad pronosticada de la clase positiva
  


- Interpretaci贸n:
  Un Log Loss bajo indica que las probabilidades predichas est谩n cerca de los valores reales. Un valor alto indica que las probabilidades predichas est谩n alejadas de la realidad, lo que refleja un modelo menos confiable.

#### 7. Matthews Correlation Coefficient (MCC)
Mide la calidad de la clasificaci贸n binaria teniendo en cuenta todos los elementos de la matriz de confusi贸n (verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos). Es una m茅trica equilibrada que es adecuada incluso para conjuntos de datos desbalanceados.

- Formula:

- Interpretaci贸n:
  Un valor de MCC cercano a 1 indica una excelente clasificaci贸n, mientras que valores cercanos a -1 indican una clasificaci贸n completamente incorrecta, y 0 sugiere que el modelo no tiene una relaci贸n significativa con la variable de salida.
  
#### 8. Specificity 
Mide la capacidad del modelo para identificar correctamente los casos negativos (es decir, evitar falsos positivos). Es lo contrario al recall, pero enfocado en los negativos.

- Formula:

- Interpretaci贸n:
  Una alta especificidad significa que el modelo es bueno para identificar los casos negativos correctamente, evitando que las instancias negativas sean clasificadas err贸neamente como positivas. Es importante cuando los falsos positivos tienen consecuencias graves.


### Resultados de evaluaci贸n

1. XGBoost
   
3. MLPClassifier (Perceptr贸n Multicapa)
4. LightGBM
5. Random Forest
6. Regresi贸n Log铆stica

Tabla que muestra los resultados de evaluaci贸n del modelo baseline, incluyendo las m茅tricas de evaluaci贸n.

## An谩lisis de los resultados

1. XGBoost

- Fortalezas: El modelo XGBoost muestra una precisi贸n perfecta (1.00), lo que sugiere que es extremadamente efectivo para identificar los casos positivos. El AUC-ROC de 0.96 indica que el modelo tiene una excelente capacidad de discriminaci贸n entre las clases. Adem谩s, el MCC de 0.79 es alto, lo que refleja un buen desempe帽o general del modelo en t茅rminos de balance entre las clases.

- Debilidades: Aunque la precisi贸n es muy alta, el recall de 0.70 indica que el modelo tiene dificultades para identificar todos los casos positivos. El log loss es relativamente bajo (0.29), lo que sugiere que el modelo realiza predicciones razonablemente confiables, pero podr铆a mejorarse en t茅rminos de la estimaci贸n de probabilidades.
  
2. MLPClassifier (Perceptr贸n Multicapa)

- Fortalezas: El modelo tiene un excelente rendimiento en t茅rminos de precisi贸n (0.92) y recall (0.76), lo que indica que es efectivo tanto para identificar correctamente los positivos como para minimizar los falsos negativos. Adem谩s, el AUC-ROC de 0.93 es una se帽al de que el modelo puede discriminar bien entre las clases.
- Debilidades: Aunque el modelo muestra un buen rendimiento general, el log loss es relativamente alto (0.32), lo que sugiere que las predicciones probabil铆sticas no son tan precisas. Adem谩s, la diferencia entre precisi贸n y recall indica que puede haber algunos problemas con la identificaci贸n de todos los casos positivos.
   
3. LightGBM
- Fortalezas: LightGBM tiene un AUC-ROC muy alto (0.96), lo que indica una excelente capacidad de discriminaci贸n entre las clases. Tambi茅n presenta un log loss muy bajo (0.23), lo que refleja predicciones confiables.
- Debilidades: Aunque el modelo tiene un buen recall (0.82), su precisi贸n es menor (0.73), lo que sugiere que el modelo predice un mayor n煤mero de falsos positivos.

4. Random Forest

- Fortalezas: El modelo tiene un recall alto (0.80), lo que significa que tiene una buena capacidad para identificar casos positivos.
- Debilidades: La precisi贸n y AUC-ROC son muy bajas, lo que sugiere que el modelo est谩 cometiendo muchos falsos positivos. Adem谩s, el log loss es muy alto (0.71), lo que refleja predicciones poco confiables.
   
5. Regresi贸n Log铆stica

- Fortalezas: La regresi贸n log铆stica muestra un buen rendimiento en t茅rminos de recall (0.72), lo que indica que el modelo es efectivo para identificar los casos positivos.
- Debilidades: La precisi贸n y el AUC-ROC son relativamente bajos, lo que sugiere que el modelo no discrimina bien entre las clases. El log loss es alto, lo que refleja predicciones inexactas.

## Conclusiones

Conclusiones generales sobre el rendimiento del modelo baseline y posibles 谩reas de mejora.

1. XGBoost
Es un modelo robusto con excelentes resultados en t茅rminos de precisi贸n y AUC-ROC. Sin embargo, el recall podr铆a mejorarse para garantizar que se identifiquen m谩s casos positivos. Este modelo es ideal para aplicaciones en las que la precisi贸n es m谩s importante que el recall.
   
2. MLPClassifier (Perceptr贸n Multicapa)

Muestra un excelente equilibrio entre precisi贸n y recall, siendo adecuado para problemas en los que es crucial identificar correctamente los casos positivos sin perder demasiados. Su rendimiento en t茅rminos de AUC-ROC tambi茅n es muy bueno.

3. LightGBM

Es un modelo eficiente y r谩pido, con un alto AUC-ROC. Sin embargo, su precisi贸n podr铆a mejorarse, especialmente en escenarios en los que la reducci贸n de falsos positivos es cr铆tica.
   
4. Random Forest

Aunque el modelo tiene un buen recall, su baja precisi贸n y AUC-ROC indican que necesita ajustes significativos para mejorar su desempe帽o general.
   
5. Regresi贸n Log铆stica

La regresi贸n log铆stica es un modelo b谩sico que, aunque adecuado para problemas simples, no es tan preciso como otros modelos m谩s complejos como XGBoost o MLPClassifier.


## Referencias

Lista de referencias utilizadas para construir el modelo baseline y evaluar su rendimiento.

Espero que te sea 煤til esta plantilla. Recuerda que puedes adaptarla a las necesidades espec铆ficas de tu proyecto.
