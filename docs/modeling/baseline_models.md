![Descripci√≥n de la imagen](images/Falla-cardiaca.jpg)

# Reporte del Modelo Baseline

Este documento contiene los resultados de los modelos entrenados.

## Descripci√≥n de los modelos

1. XGBoost
XGBoost (Extreme Gradient Boosting) es un algoritmo basado en √°rboles de decisi√≥n que utiliza un enfoque de ensamble para mejorar la precisi√≥n del modelo. Se construyen varios √°rboles de decisi√≥n de manera secuencial, y cada nuevo √°rbol intenta corregir los errores cometidos por los √°rboles anteriores. Este modelo es altamente eficiente, y es muy utilizado en competencias de machine learning debido a su capacidad para manejar tanto datos lineales como no lineales. Adem√°s, XGBoost es conocido por su velocidad y precisi√≥n, y es particularmente √∫til para grandes vol√∫menes de datos.

2. MLPClassifier (Perceptr√≥n Multicapa)
El MLPClassifier es un tipo de red neuronal que utiliza m√∫ltiples capas de perceptrones para procesar datos de entrada y realizar clasificaciones. Este modelo es capaz de aprender patrones complejos en los datos, lo que lo hace adecuado para problemas no lineales. A diferencia de los √°rboles de decisi√≥n, las redes neuronales pueden capturar relaciones m√°s complejas entre las caracter√≠sticas de entrada. El MLPClassifier se entrena utilizando el algoritmo de retropropagaci√≥n y es muy flexible en cuanto a la arquitectura de las redes neuronales.

3. LightGBM
LightGBM (Light Gradient Boosting Machine) es otro algoritmo basado en boosting, pero se diferencia de XGBoost en que es m√°s r√°pido y consume menos memoria. Utiliza una t√©cnica de histogramas para reducir el costo computacional, lo que lo hace eficiente con grandes vol√∫menes de datos. LightGBM es particularmente √∫til para problemas en los que se manejan grandes conjuntos de datos y se necesitan tiempos de entrenamiento r√°pidos.

4. Random Forest
Random Forest es un modelo de ensamble que utiliza m√∫ltiples √°rboles de decisi√≥n para mejorar la precisi√≥n general del modelo. Cada √°rbol en el bosque es entrenado en un subconjunto aleatorio de los datos, y luego se realiza una votaci√≥n para determinar la predicci√≥n final. Este enfoque ayuda a reducir el sobreajuste, haciendo que el modelo sea robusto incluso con datos ruidosos.

5. Regresi√≥n Log√≠stica
La regresi√≥n log√≠stica es un modelo de clasificaci√≥n binaria que estima la probabilidad de que una entrada pertenezca a una clase espec√≠fica. Este modelo es muy simple y eficiente para problemas de clasificaci√≥n, pero generalmente tiene un rendimiento inferior cuando los datos no son lineales.


## Variables de entrada

Lista de las variables de entrada utilizadas en el modelo.

- time
- ejection_fraction
- serum_creatinine

## Variable objetivo

Nombre de la variable objetivo utilizada en el modelo.

- DEATH_EVENT

## Evaluaci√≥n del modelo

### M√©tricas de evaluaci√≥n

Descripci√≥n de las m√©tricas utilizadas para evaluar el rendimiento del modelo.

#### 1. Accuracy
Mide la proporci√≥n de predicciones correctas sobre el total de predicciones realizadas. Es decir, cu√°ntas veces el modelo acert√≥ entre todos los casos.

- Formula:![Descripci√≥n de la imagen](images/FormulaAcurracy.png)

  TP = Verdaderos positivos
  TN = Verdaderos negativos
  FP = Falsos positivos
  FN = Falsos negativos

- Interpretaci√≥n:
  Una precisi√≥n del 100% indica que el modelo hizo todas las predicciones correctas, pero puede ser enga√±osa si las clases est√°n desbalanceadas.

#### 2. Precision 
Mide la proporci√≥n de predicciones positivas correctas sobre todas las predicciones que el modelo hizo como positivas. Es √∫til cuando el costo de un falso positivo es alto.

- Formula:![Descripci√≥n de la imagen](images/FormulaPrecision.png)
  
- Interpretaci√≥n:
   Una alta precisi√≥n significa que cuando el modelo predice positivo, es muy probable que est√© en lo cierto. Se usa cuando es m√°s importante evitar que un falso positivo ocurra.

#### 3. Recall  
Mide la proporci√≥n de casos positivos reales que el modelo fue capaz de identificar correctamente. Es √∫til cuando el costo de un falso negativo es alto.

- Formula:![Descripci√≥n de la imagen](images/FormulaRecall.png)
  
- Interpretaci√≥n:
   Un alto recall significa que el modelo es bueno para identificar casos positivos, incluso si a veces comete falsos positivos. Es cr√≠tico en situaciones donde perder casos positivos (falsos negativos) tiene consecuencias graves.

#### 4. F1 Score  
Es el promedio arm√≥nico entre la precisi√≥n y el recall, y se utiliza cuando es necesario un balance entre ambos. Un puntaje F1 alto indica que tanto la precisi√≥n como el recall son buenos.

- Formula:![Descripci√≥n de la imagen](images/FormulaF1.png)
  
- Interpretaci√≥n:
   El F1 es particularmente √∫til cuando se enfrentan a datos desbalanceados (m√°s instancias de una clase que de otra) y cuando tanto los falsos positivos como los falsos negativos tienen un impacto significativo.

#### 5. AUC-ROC  
Mide la capacidad del modelo para distinguir entre las clases, calculando el √°rea bajo la curva ROC (Receiver Operating Characteristic), que es un gr√°fico que muestra la tasa de verdaderos positivos frente a la tasa de falsos positivos.

- Interpretaci√≥n:
  Un AUC cercano a 1 indica que el modelo tiene una buena capacidad para diferenciar entre las clases. Un AUC de 0.5 indica que el modelo no tiene capacidad predictiva mejor que el azar.

#### 6. Log Loss  
Eval√∫a la calidad de las probabilidades de predicci√≥n del modelo, penalizando las predicciones incorrectas con mayor severidad. Se usa principalmente en problemas de clasificaci√≥n probabil√≠stica.

- Formula:![Descripci√≥n de la imagen](images/FormulaLogLoss.png)
  yi es el valor real de la clase (0 o 1)
  ùëùùëñ es la probabilidad pronosticada de la clase positiva
  
- Interpretaci√≥n:
  Un Log Loss bajo indica que las probabilidades predichas est√°n cerca de los valores reales. Un valor alto indica que las probabilidades predichas est√°n alejadas de la realidad, lo que refleja un modelo menos confiable.

#### 7. Matthews Correlation Coefficient (MCC)
Mide la calidad de la clasificaci√≥n binaria teniendo en cuenta todos los elementos de la matriz de confusi√≥n (verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos). Es una m√©trica equilibrada que es adecuada incluso para conjuntos de datos desbalanceados.

- Formula:![Descripci√≥n de la imagen](images/FormulaMCC.png)

- Interpretaci√≥n:
  Un valor de MCC cercano a 1 indica una excelente clasificaci√≥n, mientras que valores cercanos a -1 indican una clasificaci√≥n completamente incorrecta, y 0 sugiere que el modelo no tiene una relaci√≥n significativa con la variable de salida.
  
#### 8. Specificity 
Mide la capacidad del modelo para identificar correctamente los casos negativos (es decir, evitar falsos positivos). Es lo contrario al recall, pero enfocado en los negativos.

- Formula:![Descripci√≥n de la imagen](images/FormulaSpecificity.png)

- Interpretaci√≥n:
  Una alta especificidad significa que el modelo es bueno para identificar los casos negativos correctamente, evitando que las instancias negativas sean clasificadas err√≥neamente como positivas. Es importante cuando los falsos positivos tienen consecuencias graves.


### Resultados de evaluaci√≥n

![Descripci√≥n de la imagen](images/ValoresMetricas.png)
![Descripci√≥n de la imagen](images/GraficaComparacionModelos.png)


Tabla que muestra los resultados de las metricas de evaluaci√≥n de los modelos 

## An√°lisis de los resultados

1. XGBoost

- Fortalezas: El modelo XGBoost muestra una precisi√≥n perfecta (1.00), lo que sugiere que es extremadamente efectivo para identificar los casos positivos. El AUC-ROC de 0.96 indica que el modelo tiene una excelente capacidad de discriminaci√≥n entre las clases. Adem√°s, el MCC de 0.79 es alto, lo que refleja un buen desempe√±o general del modelo en t√©rminos de balance entre las clases.

- Debilidades: Aunque la precisi√≥n es muy alta, el recall de 0.70 indica que el modelo tiene dificultades para identificar todos los casos positivos. El log loss es relativamente bajo (0.29), lo que sugiere que el modelo realiza predicciones razonablemente confiables, pero podr√≠a mejorarse en t√©rminos de la estimaci√≥n de probabilidades.
  
2. MLPClassifier (Perceptr√≥n Multicapa)

- Fortalezas: El modelo tiene un excelente rendimiento en t√©rminos de precisi√≥n (0.92) y recall (0.76), lo que indica que es efectivo tanto para identificar correctamente los positivos como para minimizar los falsos negativos. Adem√°s, el AUC-ROC de 0.93 es una se√±al de que el modelo puede discriminar bien entre las clases.
- Debilidades: Aunque el modelo muestra un buen rendimiento general, el log loss es relativamente alto (0.32), lo que sugiere que las predicciones probabil√≠sticas no son tan precisas. Adem√°s, la diferencia entre precisi√≥n y recall indica que puede haber algunos problemas con la identificaci√≥n de todos los casos positivos.
   
3. LightGBM
- Fortalezas: LightGBM tiene un AUC-ROC muy alto (0.96), lo que indica una excelente capacidad de discriminaci√≥n entre las clases. Tambi√©n presenta un log loss muy bajo (0.23), lo que refleja predicciones confiables.
- Debilidades: Aunque el modelo tiene un buen recall (0.82), su precisi√≥n es menor (0.73), lo que sugiere que el modelo predice un mayor n√∫mero de falsos positivos.

4. Random Forest

- Fortalezas: El modelo tiene un recall alto (0.80), lo que significa que tiene una buena capacidad para identificar casos positivos.
- Debilidades: La precisi√≥n y AUC-ROC son muy bajas, lo que sugiere que el modelo est√° cometiendo muchos falsos positivos. Adem√°s, el log loss es muy alto (0.71), lo que refleja predicciones poco confiables.
   
5. Regresi√≥n Log√≠stica

- Fortalezas: La regresi√≥n log√≠stica muestra un buen rendimiento en t√©rminos de recall (0.72), lo que indica que el modelo es efectivo para identificar los casos positivos.
- Debilidades: La precisi√≥n y el AUC-ROC son relativamente bajos, lo que sugiere que el modelo no discrimina bien entre las clases. El log loss es alto, lo que refleja predicciones inexactas.

## Conclusiones

Conclusiones generales sobre el rendimiento del modelo baseline y posibles √°reas de mejora.

1. XGBoost
Es un modelo robusto con excelentes resultados en t√©rminos de precisi√≥n y AUC-ROC. Sin embargo, el recall podr√≠a mejorarse para garantizar que se identifiquen m√°s casos positivos. Este modelo es ideal para aplicaciones en las que la precisi√≥n es m√°s importante que el recall.
   
2. MLPClassifier (Perceptr√≥n Multicapa)

Muestra un excelente equilibrio entre precisi√≥n y recall, siendo adecuado para problemas en los que es crucial identificar correctamente los casos positivos sin perder demasiados. Su rendimiento en t√©rminos de AUC-ROC tambi√©n es muy bueno.

3. LightGBM

Es un modelo eficiente y r√°pido, con un alto AUC-ROC. Sin embargo, su precisi√≥n podr√≠a mejorarse, especialmente en escenarios en los que la reducci√≥n de falsos positivos es cr√≠tica.
   
4. Random Forest

Aunque el modelo tiene un buen recall, su baja precisi√≥n y AUC-ROC indican que necesita ajustes significativos para mejorar su desempe√±o general.
   
5. Regresi√≥n Log√≠stica

La regresi√≥n log√≠stica es un modelo b√°sico que, aunque adecuado para problemas simples, no es tan preciso como otros modelos m√°s complejos como XGBoost o MLPClassifier.

- En conclusi√≥n, XGBoost emerge como el modelo m√°s eficiente en t√©rminos generales debido a su alto AUC-ROC y su precisi√≥n perfecta, lo que lo hace ideal para tareas de clasificaci√≥n binaria donde la discriminaci√≥n entre clases es clave. No obstante, dependiendo de la aplicaci√≥n espec√≠fica, MLPClassifier y LightGBM tambi√©n ofrecen ventajas, como un mejor balance entre precisi√≥n y recall, especialmente cuando el enfoque est√° en detectar todos los casos positivos sin importar tanto el costo de los falsos positivos.


## Referencias

- matplotlib:

Matplotlib es una biblioteca para la visualizaci√≥n de gr√°ficos en Python. Es ampliamente utilizada para crear gr√°ficos est√°ticos, animados e interactivos.
Referencia:
Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science & Engineering, 9(3), 90-95.
DOI: 10.1109/MCSE.2007.55

- xgboost:
XGBoost es un algoritmo de aprendizaje autom√°tico basado en √°rboles de decisi√≥n, especialmente eficiente para clasificaci√≥n y regresi√≥n.
Referencia:
Chen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785‚Äì794.
DOI: 10.1145/2939672.2939785

- colorama:
Colorama es una biblioteca que permite utilizar colores en la salida de la terminal o consola, mejorando la legibilidad de los mensajes.
Referencia:
Colorama Documentation. (2021). https://pypi.org/project/colorama/

- scikit-learn:
scikit-learn es una biblioteca de Python que proporciona herramientas para miner√≠a de datos y an√°lisis de datos. Incluye varios algoritmos de aprendizaje autom√°tico y herramientas de evaluaci√≥n de modelos.
Referencia:
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, √â. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12, 2825-2830.
URL: https://scikit-learn.org/

- imblearn (imbalanced-learn):

imbalanced-learn es una biblioteca de Python para manejar conjuntos de datos desbalanceados mediante t√©cnicas de sobremuestreo y submuestreo.
Referencia:
Lema√Ætre, G., Nogueira, F., & Aridas, C. K. (2017). Imbalanced-learn: A Python toolbox to tackle the curse of imbalanced datasets in machine learning. Journal of Machine Learning Research, 18(1), 559-563.
URL: https://imbalanced-learn.org/

- mlxtend:

mlxtend es una biblioteca que ofrece una colecci√≥n de extensiones √∫tiles para scikit-learn, incluyendo visualizaci√≥n de matrices de confusi√≥n y otras herramientas.
Referencia:
Raschka, S., & Mirjalili, V. (2017). Python Machine Learning. Packt Publishing.
URL: https://rasbt.github.io/mlxtend/

- lightgbm:

LightGBM es una implementaci√≥n eficiente de un algoritmo de aprendizaje basado en gradiente boosting para clasificaci√≥n y regresi√≥n.
Referencia:
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., & Ma, W. (2017). LightGBM: A highly efficient gradient boosting decision tree. Advances in Neural Information Processing Systems, 30.
URL: https://lightgbm.readthedocs.io/

- MLPClassifier (de scikit-learn):

MLPClassifier es un clasificador basado en redes neuronales multicapa (MLP) disponible en scikit-learn.
Referencia:
B. Sch√∂lkopf, A. Smola, et al. (2002). Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. MIT Press.
URL: https://scikit-learn.org/stable/modules/neural_networks_supervised.html#mlpclassifier

- Accuracy:

Chicco, D., & Jurman, G. (2020). The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC Genomics, 21(1), 6.
DOI: 10.1186/s12864-019-6250-3

- Precision:

Powers, D. M. W. (2011). Evaluation: from precision, recall and F-measure to ROC, informedness, markedness & correlation. Journal of Machine Learning Technologies, 2(1), 37-63.
URL: https://arxiv.org/abs/2010.15948

- Recall:

Sokolova, M., & Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. Information Processing & Management, 45(4), 427-437.
DOI: 10.1016/j.ipm.2009.03.002

- F1 Score:

Van Rijsbergen, C. J. (1979). Information Retrieval (2nd ed.). Butterworths.
ISBN: 978-0408704132

- AUC-ROC:

Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874.
DOI: 10.1016/j.patrec.2005.10.010

- Log Loss:

Nogueira, M. (2020). Evaluation Metrics for Classification Algorithms. Springer.
ISBN: 978-3030289045

- Matthews Correlation Coefficient (MCC):

Matthews, B. W. (1975). Comparison of the predicted and observed binary classification rates: a new measure of the accuracy of predictions. Ecology, 56(1), 1-11.
DOI: 10.2307/1936166

- Specificity:

Powers, D. M. W. (2011). Evaluation: from precision, recall and F-measure to ROC, informedness, markedness & correlation. Journal of Machine Learning Technologies, 2(1), 37-63.
URL: https://arxiv.org/abs/2010.15948
